{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore, rankdata\n",
    "import torch.optim\n",
    "\n",
    "from SAC_deepQnet import SACAgent\n",
    "\n",
    "from SAC_evaluate import do_eval, do_test\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================== small function===============================\n",
    "from scipy.stats import zscore, rankdata\n",
    "\n",
    "\n",
    "def my_zscore(x):\n",
    "    return zscore(x, ddof=1), np.mean(x, axis=0), np.std(x, axis=0, ddof=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####  generated state  ####\n",
      "####  Generating Actions  ####\n",
      "####  Generate Rewards  ####\n",
      "377029\n",
      "####  Generate trajectory  ####\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "seed = 42\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "if __name__ == '__main__':\n",
    "    start = time.perf_counter()\n",
    "    with open('step_4_start_mimiciv_try.pkl', 'rb') as file:\n",
    "        MIMICtable = pickle.load(file)\n",
    "\n",
    "    ##################### Pengaturan parameter model##############################\n",
    "    # Training Parameters\n",
    "    num_epoch = 151\n",
    "    gamma = 0.99\n",
    "    beat1 = 0\n",
    "    beat2 = 0.6\n",
    "    beta3 = 0.3\n",
    "    lr = 3e-5\n",
    "    reward_value = 24\n",
    "    beta = [beat1, beat2, beta3]\n",
    "    icustayidlist = MIMICtable['stay_id']\n",
    "    # list of unique icustayids from MIMIC unique icustayid list\n",
    "    icuuniqueids = np.unique(icustayidlist)\n",
    "    reformat5 = MIMICtable.values.copy()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    print('####  generated state  ####')\n",
    "\n",
    "    # -----------------------Filtered features = 37--------------------------------\n",
    "    colnorm = ['SOFA', 'age', 'Weight_kg', 'GCS', 'HR', 'SysBP', 'MeanBP', 'DiaBP', 'RR', 'Temp_C',\n",
    "               'Sodium', 'Chloride', 'Glucose', 'Calcium', 'Hb', 'WBC_count', 'Platelets_count',\n",
    "               'PTT', 'PT', 'Arterial_pH', 'paO2', 'paCO2', 'HCO3', 'Arterial_lactate', 'Shock_Index',\n",
    "               'PaO2_FiO2', 'cumulated_balance', 'CO2_mEqL', 'Ionised_Ca']\n",
    "    # 8个指标\n",
    "    collog = ['SpO2', 'BUN', 'Creatinine', 'SGOT',\n",
    "              'Total_bili', 'INR', 'input_total', 'output_total']\n",
    "\n",
    "    colnorm = np.where(np.isin(MIMICtable.columns, colnorm))[0]\n",
    "    collog = np.where(np.isin(MIMICtable.columns, collog))[0]\n",
    "\n",
    "    scaleMIMIC = np.concatenate([zscore(reformat5[:, colnorm], ddof=1),\n",
    "                                 zscore(np.log(0.1 + reformat5[:, collog]), ddof=1)], axis=1)\n",
    "\n",
    "    # scaleMIMIC = zscore(reformat5[:, colnorm], ddof=1)\n",
    "\n",
    "    train = np.load('train_mimiciv.npy')\n",
    "    validat = np.load('validation_mimiciv.npy')\n",
    "    test = np.load('test_mimiciv.npy')\n",
    "\n",
    "    Xvalidat = scaleMIMIC[validat, :]\n",
    "    blocsvalidat = reformat5[validat, 0]\n",
    "    ptidvalidat = reformat5[validat, 1]\n",
    "\n",
    "    Xtrain = scaleMIMIC[train, :]\n",
    "    Xtest = scaleMIMIC[test, :]\n",
    "    blocstrain = reformat5[train, 0]  # Serial number\n",
    "    bloctest = reformat5[test, 0]\n",
    "    ptidtrain = reformat5[train, 1]  # Patient number\n",
    "    ptidtest = reformat5[test, 1]\n",
    "\n",
    "    # *************************\n",
    "    RNNstate = Xtrain  # ***\n",
    "\n",
    "    print('####  Generating Actions  ####')\n",
    "\n",
    "    # --- Ambil kolom indeks IV dan vasopressor ---\n",
    "    iol = MIMICtable.columns.get_loc('input_4hourly')      # IV fluid column\n",
    "    vcl = MIMICtable.columns.get_loc('max_dose_vaso')      # Vasopressor column\n",
    "\n",
    "    # Ambil nilai mentah (raw)\n",
    "    iv_raw = reformat5[:, iol].reshape(-1, 1)\n",
    "    vaso_raw = reformat5[:, vcl].reshape(-1, 1)\n",
    "\n",
    "    # Lakukan log1p transform (lebih aman untuk data dengan nol)\n",
    "    iv_log = np.log1p(iv_raw)\n",
    "    vaso_log = np.log1p(vaso_raw)\n",
    "\n",
    "    # Hitung mean dan std di domain log\n",
    "    mean_log_iv = iv_log.mean()\n",
    "    std_log_iv = iv_log.std(ddof=1)\n",
    "\n",
    "    mean_log_vaso = vaso_log.mean()\n",
    "    std_log_vaso = vaso_log.std(ddof=1)\n",
    "\n",
    "    # Normalisasi dengan z-score\n",
    "    iv_norm = (iv_log - mean_log_iv) / std_log_iv\n",
    "    vaso_norm = (vaso_log - mean_log_vaso) / std_log_vaso\n",
    "\n",
    "    # Gabungkan sebagai continuous action\n",
    "    continuous_actions = np.concatenate([iv_norm, vaso_norm], axis=1)\n",
    "\n",
    "    # Simpan untuk inverse transform saat inference\n",
    "    norm_stats = {\n",
    "        \"mean_log_iv\": float(mean_log_iv),\n",
    "        \"std_log_iv\": float(std_log_iv),\n",
    "        \"mean_log_vaso\": float(mean_log_vaso),\n",
    "        \"std_log_vaso\": float(std_log_vaso)\n",
    "    }\n",
    "    with open('SAC-algorithm/action_norm_stats.pkl', 'wb') as f:\n",
    "        pickle.dump(norm_stats, f)\n",
    "\n",
    "    # Split actions untuk train/valid/test\n",
    "    actionbloctrain = continuous_actions[train]\n",
    "    actionblocvalidat = continuous_actions[validat]\n",
    "    actionbloctest = continuous_actions[test]\n",
    "\n",
    "    # =================incentives============================\n",
    "    print('####  Generate Rewards  ####')\n",
    "    outcome = 9\n",
    "    Y90 = reformat5[train, outcome]\n",
    "    reward_value = 24\n",
    "    r = np.array([reward_value, -reward_value]).reshape(1, -1)\n",
    "    r2 = r * (2 * (1 - Y90.reshape(-1, 1)) - 1)  #  Skor reward\n",
    "\n",
    "    # -----Incentive function preparation-----------------------------\n",
    "    SOFA = reformat5[train, 57]  # ***\n",
    "    R3 = r2[:, 0]\n",
    "    R4 = (R3 + reward_value) / (2 * reward_value)\n",
    "    c = 0\n",
    "    bloc_max = max(blocstrain)\n",
    "\n",
    "    # ================Build state & & next state sequence lists Generate strategy trajectories=================================\n",
    "    print(RNNstate.shape[0])\n",
    "\n",
    "    print('####  Generate trajectory  ####')\n",
    "    statesize = int(RNNstate.shape[1])\n",
    "    states = np.zeros(\n",
    "        (np.floor(RNNstate.shape[0] * 1.2).astype('int64'), statesize))\n",
    "    actions = np.zeros(\n",
    "        (np.floor(RNNstate.shape[0] * 1.2).astype('int64'), 2), dtype=np.float32)\n",
    "    next_actions = np.zeros(\n",
    "        (np.floor(RNNstate.shape[0] * 1.2).astype('int64'), 2), dtype=np.float32)\n",
    "    rewards = np.zeros((np.floor(RNNstate.shape[0] * 1.2).astype('int64'), 1))\n",
    "    next_states = np.zeros(\n",
    "        (np.floor(RNNstate.shape[0] * 1.2).astype('int64'), statesize))\n",
    "    done_flags = np.zeros(\n",
    "        (np.floor(RNNstate.shape[0] * 1.2).astype('int64'), 1))\n",
    "    bloc_num = np.zeros((np.floor(RNNstate.shape[0] * 1.2).astype('int64'), 1))\n",
    "    blocnum1 = 1\n",
    "\n",
    "    bloc_num_reward = 0\n",
    "    for i in range(RNNstate.shape[0] - 1):  # Each line of the cycle\n",
    "        states[c] = RNNstate[i, :]\n",
    "        actions[c] = actionbloctrain[i]\n",
    "        bloc_num[c] = blocnum1\n",
    "        if (blocstrain[i + 1] == 1):  # end of trace for this patient\n",
    "            next_states1 = np.zeros(statesize)\n",
    "            next_actions1 = -1\n",
    "            done_flags1 = 1\n",
    "            blocnum1 = blocnum1 + 1\n",
    "            bloc_num_reward += 1\n",
    "            reward1 = -beat1 * (SOFA[i]) + R3[i]\n",
    "            bloc_num_reward = 0\n",
    "        else:\n",
    "            next_states1 = RNNstate[i + 1, :]\n",
    "            next_actions1 = actionbloctrain[i + 1]\n",
    "            done_flags1 = 0\n",
    "            blocnum1 = blocnum1\n",
    "            reward1 = - beat2 * (SOFA[i + 1] - SOFA[i])\n",
    "            bloc_num_reward += 1\n",
    "        next_states[c] = next_states1\n",
    "        next_actions[c] = next_actions1\n",
    "        rewards[c] = reward1\n",
    "        done_flags[c] = done_flags1\n",
    "        c = c + 1\n",
    "    states[c] = RNNstate[c, :]\n",
    "    actions[c] = actionbloctrain[c]\n",
    "    bloc_num[c] = blocnum1\n",
    "\n",
    "    next_states1 = np.zeros(statesize)\n",
    "    next_actions1 = -1\n",
    "    done_flags1 = 1\n",
    "    blocnum1 = blocnum1 + 1\n",
    "    bloc_num_reward += 1\n",
    "    reward1 = -beat1 * (SOFA[c]) + R3[c]\n",
    "\n",
    "    bloc_num_reward = 0\n",
    "    next_states[c] = next_states1\n",
    "    next_actions[c] = next_actions1\n",
    "    rewards[c] = reward1\n",
    "    done_flags[c] = done_flags1\n",
    "    c = c + 1\n",
    "\n",
    "    bloc_num[c] = blocnum1\n",
    "    bloc_num = bloc_num[:c, :]\n",
    "    states = states[: c, :]\n",
    "    next_states = next_states[: c, :]\n",
    "    actions = actions[: c, :]\n",
    "    next_actions = next_actions[: c, :]\n",
    "    rewards = rewards[: c, :]\n",
    "    done_flags = done_flags[: c, :]\n",
    "    bloc_num = np.squeeze(bloc_num)\n",
    "    actions = np.squeeze(actions)\n",
    "    rewards = np.squeeze(rewards)\n",
    "    done_flags = np.squeeze(done_flags)\n",
    "    batch_size = 16\n",
    "    state = torch.FloatTensor(states).to(device)\n",
    "    next_state = torch.FloatTensor(next_states).to(device)\n",
    "    action = torch.FloatTensor(actions).to(device)\n",
    "    next_action = torch.FloatTensor(next_actions).to(device)\n",
    "    reward = torch.FloatTensor(rewards).to(device)\n",
    "    done = torch.FloatTensor(done_flags).to(device)\n",
    "    SOFAS = torch.LongTensor(SOFA).to(device)\n",
    "    batchs = (state, next_state, action, next_action,\n",
    "              reward, done, bloc_num, SOFAS)\n",
    "\n",
    "# =================Training model, master cycle==================\n",
    "Y90_validat = reformat5[validat, outcome]\n",
    "SOFA_validat = reformat5[validat, 57]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####  generated state  ####\n",
      "####  Generating Actions  ####\n",
      "####  Generate Rewards  ####\n",
      "377029\n",
      "####  Generate trajectory  ####\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "seed = 42\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "if __name__ == '__main__':\n",
    "    start = time.perf_counter()\n",
    "    with open('step_4_start_mimiciv_try.pkl', 'rb') as file:\n",
    "        MIMICtable = pickle.load(file)\n",
    "\n",
    "    ##################### Pengaturan parameter model##############################\n",
    "    # Training Parameters\n",
    "    num_epoch = 151\n",
    "    gamma = 0.99\n",
    "    beat1 = 0\n",
    "    beat2 = 0.6\n",
    "    beta3 = 0.3\n",
    "    lr = 3e-5\n",
    "    reward_value = 24\n",
    "    beta = [beat1, beat2, beta3]\n",
    "    icustayidlist = MIMICtable['stay_id']\n",
    "    # list of unique icustayids from MIMIC unique icustayid list\n",
    "    icuuniqueids = np.unique(icustayidlist)\n",
    "    reformat5 = MIMICtable.values.copy()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    print('####  generated state  ####')\n",
    "\n",
    "    # -----------------------Filtered features = 37--------------------------------\n",
    "    colnorm = ['SOFA', 'age', 'Weight_kg', 'GCS', 'HR', 'SysBP', 'MeanBP', 'DiaBP', 'RR', 'Temp_C',\n",
    "               'Sodium', 'Chloride', 'Glucose', 'Calcium', 'Hb', 'WBC_count', 'Platelets_count',\n",
    "               'PTT', 'PT', 'Arterial_pH', 'paO2', 'paCO2', 'HCO3', 'Arterial_lactate', 'Shock_Index',\n",
    "               'PaO2_FiO2', 'cumulated_balance', 'CO2_mEqL', 'Ionised_Ca']\n",
    "    # 8个指标\n",
    "    collog = ['SpO2', 'BUN', 'Creatinine', 'SGOT',\n",
    "              'Total_bili', 'INR', 'input_total', 'output_total']\n",
    "\n",
    "    colnorm = np.where(np.isin(MIMICtable.columns, colnorm))[0]\n",
    "    collog = np.where(np.isin(MIMICtable.columns, collog))[0]\n",
    "\n",
    "    scaleMIMIC = np.concatenate([zscore(reformat5[:, colnorm], ddof=1),\n",
    "                                 zscore(np.log(0.1 + reformat5[:, collog]), ddof=1)], axis=1)\n",
    "\n",
    "    # scaleMIMIC = zscore(reformat5[:, colnorm], ddof=1)\n",
    "\n",
    "    train = np.load('train_mimiciv.npy')\n",
    "    validat = np.load('validation_mimiciv.npy')\n",
    "    test = np.load('test_mimiciv.npy')\n",
    "\n",
    "    Xvalidat = scaleMIMIC[validat, :]\n",
    "    blocsvalidat = reformat5[validat, 0]\n",
    "    ptidvalidat = reformat5[validat, 1]\n",
    "\n",
    "    Xtrain = scaleMIMIC[train, :]\n",
    "    Xtest = scaleMIMIC[test, :]\n",
    "    blocstrain = reformat5[train, 0]  # Serial number\n",
    "    bloctest = reformat5[test, 0]\n",
    "    ptidtrain = reformat5[train, 1]  # Patient number\n",
    "    ptidtest = reformat5[test, 1]\n",
    "\n",
    "    # *************************\n",
    "    RNNstate = Xtrain  # ***\n",
    "\n",
    "    print('####  Generating Actions  ####')\n",
    "\n",
    "    # --- Ambil kolom indeks IV dan vasopressor ---\n",
    "    iol = MIMICtable.columns.get_loc('input_4hourly')      # IV fluid column\n",
    "    vcl = MIMICtable.columns.get_loc('max_dose_vaso')      # Vasopressor column\n",
    "\n",
    "    # Ambil nilai mentah (raw)\n",
    "    iv_raw = reformat5[:, iol].reshape(-1, 1)\n",
    "    vaso_raw = reformat5[:, vcl].reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    # Lakukan log1p transform (lebih aman untuk data dengan nol)\n",
    "    iv_log = np.log1p(iv_raw)\n",
    "    vaso_log = np.log1p(vaso_raw)\n",
    "\n",
    "    # Hitung mean dan std di domain log\n",
    "    mean_log_iv = iv_log.mean()\n",
    "    std_log_iv = iv_log.std(ddof=1)\n",
    "\n",
    "    mean_log_vaso = vaso_log.mean()\n",
    "    std_log_vaso = vaso_log.std(ddof=1)\n",
    "\n",
    "    # Normalisasi dengan z-score\n",
    "    iv_norm = (iv_log - mean_log_iv) / std_log_iv\n",
    "    vaso_norm = (vaso_log - mean_log_vaso) / std_log_vaso\n",
    "\n",
    "    # Gabungkan sebagai continuous action\n",
    "    continuous_actions = np.concatenate([iv_norm, vaso_norm], axis=1)\n",
    "\n",
    "    # Simpan untuk inverse transform saat inference\n",
    "    norm_stats = {\n",
    "        \"mean_log_iv\": float(mean_log_iv),\n",
    "        \"std_log_iv\": float(std_log_iv),\n",
    "        \"mean_log_vaso\": float(mean_log_vaso),\n",
    "        \"std_log_vaso\": float(std_log_vaso)\n",
    "    }\n",
    "    with open('SAC-algorithm/action_norm_stats.pkl', 'wb') as f:\n",
    "        pickle.dump(norm_stats, f)\n",
    "\n",
    "    # Split actions untuk train/valid/test\n",
    "    actionbloctrain = continuous_actions[train]\n",
    "    actionblocvalidat = continuous_actions[validat]\n",
    "    actionbloctest = continuous_actions[test]\n",
    "\n",
    "    # =================incentives============================\n",
    "    print('####  Generate Rewards  ####')\n",
    "    outcome = 9\n",
    "    Y90 = reformat5[train, outcome]\n",
    "    reward_value = 24\n",
    "    r = np.array([reward_value, -reward_value]).reshape(1, -1)\n",
    "    r2 = r * (2 * (1 - Y90.reshape(-1, 1)) - 1)  #  Skor reward\n",
    "\n",
    "    # -----Incentive function preparation-----------------------------\n",
    "    SOFA = reformat5[train, 57]  # ***\n",
    "    R3 = r2[:, 0]\n",
    "    R4 = (R3 + reward_value) / (2 * reward_value)\n",
    "    c = 0\n",
    "    bloc_max = max(blocstrain)\n",
    "\n",
    "    # ================Build state & & next state sequence lists Generate strategy trajectories=================================\n",
    "    print(RNNstate.shape[0])\n",
    "\n",
    "    print('####  Generate trajectory  ####')\n",
    "    statesize = int(RNNstate.shape[1])\n",
    "    states = np.zeros(\n",
    "        (np.floor(RNNstate.shape[0] * 1.2).astype('int64'), statesize))\n",
    "    actions = np.zeros(\n",
    "        (np.floor(RNNstate.shape[0] * 1.2).astype('int64'), 2), dtype=np.float32)\n",
    "    next_actions = np.zeros(\n",
    "        (np.floor(RNNstate.shape[0] * 1.2).astype('int64'), 2), dtype=np.float32)\n",
    "    rewards = np.zeros((np.floor(RNNstate.shape[0] * 1.2).astype('int64'), 1))\n",
    "    next_states = np.zeros(\n",
    "        (np.floor(RNNstate.shape[0] * 1.2).astype('int64'), statesize))\n",
    "    done_flags = np.zeros(\n",
    "        (np.floor(RNNstate.shape[0] * 1.2).astype('int64'), 1))\n",
    "    bloc_num = np.zeros((np.floor(RNNstate.shape[0] * 1.2).astype('int64'), 1))\n",
    "    blocnum1 = 1\n",
    "\n",
    "    bloc_num_reward = 0\n",
    "    for i in range(RNNstate.shape[0] - 1):  # Each line of the cycle\n",
    "        states[c] = RNNstate[i, :]\n",
    "        actions[c] = actionbloctrain[i]\n",
    "        bloc_num[c] = blocnum1\n",
    "        if (blocstrain[i + 1] == 1):  # end of trace for this patient\n",
    "            next_states1 = np.zeros(statesize)\n",
    "            next_actions1 = -1\n",
    "            done_flags1 = 1\n",
    "            blocnum1 = blocnum1 + 1\n",
    "            bloc_num_reward += 1\n",
    "            reward1 = -beat1 * (SOFA[i]) + R3[i]\n",
    "            bloc_num_reward = 0\n",
    "        else:\n",
    "            next_states1 = RNNstate[i + 1, :]\n",
    "            next_actions1 = actionbloctrain[i + 1]\n",
    "            done_flags1 = 0\n",
    "            blocnum1 = blocnum1\n",
    "            reward1 = - beat2 * (SOFA[i + 1] - SOFA[i])\n",
    "            bloc_num_reward += 1\n",
    "        next_states[c] = next_states1\n",
    "        next_actions[c] = next_actions1\n",
    "        rewards[c] = reward1\n",
    "        done_flags[c] = done_flags1\n",
    "        c = c + 1\n",
    "    states[c] = RNNstate[c, :]\n",
    "    actions[c] = actionbloctrain[c]\n",
    "    bloc_num[c] = blocnum1\n",
    "\n",
    "    next_states1 = np.zeros(statesize)\n",
    "    next_actions1 = -1\n",
    "    done_flags1 = 1\n",
    "    blocnum1 = blocnum1 + 1\n",
    "    bloc_num_reward += 1\n",
    "    reward1 = -beat1 * (SOFA[c]) + R3[c]\n",
    "\n",
    "    bloc_num_reward = 0\n",
    "    next_states[c] = next_states1\n",
    "    next_actions[c] = next_actions1\n",
    "    rewards[c] = reward1\n",
    "    done_flags[c] = done_flags1\n",
    "    c = c + 1\n",
    "\n",
    "    bloc_num[c] = blocnum1\n",
    "    bloc_num = bloc_num[:c, :]\n",
    "    states = states[: c, :]\n",
    "    next_states = next_states[: c, :]\n",
    "    actions = actions[: c, :]\n",
    "    next_actions = next_actions[: c, :]\n",
    "    rewards = rewards[: c, :]\n",
    "    done_flags = done_flags[: c, :]\n",
    "    bloc_num = np.squeeze(bloc_num)\n",
    "    actions = np.squeeze(actions)\n",
    "    rewards = np.squeeze(rewards)\n",
    "    done_flags = np.squeeze(done_flags)\n",
    "    batch_size = 16\n",
    "    state = torch.FloatTensor(states).to(device)\n",
    "    next_state = torch.FloatTensor(next_states).to(device)\n",
    "    action = torch.FloatTensor(actions).to(device)\n",
    "    next_action = torch.FloatTensor(next_actions).to(device)\n",
    "    reward = torch.FloatTensor(rewards).to(device)\n",
    "    done = torch.FloatTensor(done_flags).to(device)\n",
    "    SOFAS = torch.LongTensor(SOFA).to(device)\n",
    "    batchs = (state, next_state, action, next_action,\n",
    "              reward, done, bloc_num, SOFAS)\n",
    "\n",
    "# =================Training model, master cycle==================\n",
    "Y90_validat = reformat5[validat, outcome]\n",
    "SOFA_validat = reformat5[validat, 57]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_action(norm_action, stats_path='SAC-algorithm/action_norm_stats.pkl'):\n",
    "    with open(stats_path, 'rb') as f:\n",
    "        stats = pickle.load(f)\n",
    "\n",
    "    # Ambil statistik yang benar\n",
    "    mean_log_iv = stats['mean_log_iv']\n",
    "    std_log_iv = stats['std_log_iv']\n",
    "    mean_log_vaso = stats['mean_log_vaso']\n",
    "    std_log_vaso = stats['std_log_vaso']\n",
    "\n",
    "    # Transformasi balik dari z-score ke log1p domain\n",
    "    iv_log = norm_action[:, 0] * std_log_iv + mean_log_iv\n",
    "    vaso_log = norm_action[:, 1] * std_log_vaso + mean_log_vaso\n",
    "\n",
    "    # Transformasi balik dari log1p ke domain asli\n",
    "    iv_raw = np.expm1(iv_log)\n",
    "    vaso_raw = np.expm1(vaso_log)\n",
    "\n",
    "    return np.stack([iv_raw, vaso_raw], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[1] Normalized action (z-score): IV=0.8470, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=250.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[2] Normalized action (z-score): IV=1.1151, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=500.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[3] Normalized action (z-score): IV=1.1151, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=500.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[4] Normalized action (z-score): IV=1.1151, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=500.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[5] Normalized action (z-score): IV=0.8810, Vaso=0.0574\n",
      "    Original action (raw dosage): IV=272.9996 mL, Vaso=0.0500 mcg/min\n",
      "\n",
      "[6] Normalized action (z-score): IV=-1.2965, Vaso=0.0574\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=0.0500 mcg/min\n",
      "\n",
      "[7] Normalized action (z-score): IV=1.0336, Vaso=0.0574\n",
      "    Original action (raw dosage): IV=405.0001 mL, Vaso=0.0500 mcg/min\n",
      "\n",
      "[8] Normalized action (z-score): IV=0.4742, Vaso=-0.1809\n",
      "    Original action (raw dosage): IV=95.0000 mL, Vaso=0.0160 mcg/min\n",
      "\n",
      "[9] Normalized action (z-score): IV=-1.2965, Vaso=-0.1809\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=0.0160 mcg/min\n",
      "\n",
      "[10] Normalized action (z-score): IV=-1.2965, Vaso=-0.1809\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=0.0160 mcg/min\n",
      "\n",
      "[11] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[12] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[13] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[14] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[15] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[16] Normalized action (z-score): IV=0.1441, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=40.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[17] Normalized action (z-score): IV=0.1441, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=40.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[18] Normalized action (z-score): IV=0.1441, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=40.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[19] Normalized action (z-score): IV=0.0973, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=35.3333 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[20] Normalized action (z-score): IV=-0.1154, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=20.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[21] Normalized action (z-score): IV=-0.1154, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=20.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[22] Normalized action (z-score): IV=-0.1154, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=20.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[23] Normalized action (z-score): IV=-0.3663, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=10.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[24] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[25] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[26] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[27] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[28] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[29] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[30] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[31] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[32] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[33] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[34] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[35] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[36] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[37] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[38] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[39] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[40] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[41] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[42] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[43] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[44] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[45] Normalized action (z-score): IV=-0.2288, Vaso=0.9024\n",
      "    Original action (raw dosage): IV=14.6764 mL, Vaso=0.1800 mcg/min\n",
      "\n",
      "[46] Normalized action (z-score): IV=1.3953, Vaso=1.1734\n",
      "    Original action (raw dosage): IV=1030.4714 mL, Vaso=0.2250 mcg/min\n",
      "\n",
      "[47] Normalized action (z-score): IV=1.3858, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=1005.5004 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[48] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[49] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[50] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[51] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[52] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[53] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[54] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[55] Normalized action (z-score): IV=1.5155, Vaso=0.0574\n",
      "    Original action (raw dosage): IV=1405.1403 mL, Vaso=0.0500 mcg/min\n",
      "\n",
      "[56] Normalized action (z-score): IV=0.6987, Vaso=0.2613\n",
      "    Original action (raw dosage): IV=170.2550 mL, Vaso=0.0800 mcg/min\n",
      "\n",
      "[57] Normalized action (z-score): IV=1.5391, Vaso=0.2613\n",
      "    Original action (raw dosage): IV=1493.5791 mL, Vaso=0.0800 mcg/min\n",
      "\n",
      "[58] Normalized action (z-score): IV=1.1301, Vaso=-0.0119\n",
      "    Original action (raw dosage): IV=519.7092 mL, Vaso=0.0400 mcg/min\n",
      "\n",
      "[59] Normalized action (z-score): IV=0.5597, Vaso=-0.0119\n",
      "    Original action (raw dosage): IV=118.6784 mL, Vaso=0.0400 mcg/min\n",
      "\n",
      "[60] Normalized action (z-score): IV=0.3269, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=64.6773 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[61] Normalized action (z-score): IV=0.1441, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=40.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[62] Normalized action (z-score): IV=0.1441, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=40.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[63] Normalized action (z-score): IV=1.2157, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=648.3335 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[64] Normalized action (z-score): IV=1.2263, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=666.3337 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[65] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[66] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[67] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[68] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[69] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[70] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[71] Normalized action (z-score): IV=-0.2090, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=15.5000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[72] Normalized action (z-score): IV=-0.1154, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=20.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[73] Normalized action (z-score): IV=-0.1681, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=17.3333 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[74] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[75] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[76] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[77] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[78] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[79] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[80] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[81] Normalized action (z-score): IV=0.7626, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=200.9200 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[82] Normalized action (z-score): IV=0.7626, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=200.9200 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[83] Normalized action (z-score): IV=0.8108, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=227.6234 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[84] Normalized action (z-score): IV=0.9966, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=368.0681 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[85] Normalized action (z-score): IV=0.8541, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=254.6222 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[86] Normalized action (z-score): IV=0.7608, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=200.0001 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[87] Normalized action (z-score): IV=0.7608, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=200.0001 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[88] Normalized action (z-score): IV=0.3413, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=67.1546 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[89] Normalized action (z-score): IV=-0.0936, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=21.2155 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[90] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[91] Normalized action (z-score): IV=-1.2965, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=-0.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[92] Normalized action (z-score): IV=0.7735, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=206.6667 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[93] Normalized action (z-score): IV=1.0743, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=450.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[94] Normalized action (z-score): IV=1.0223, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=393.3334 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[95] Normalized action (z-score): IV=0.4939, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=100.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[96] Normalized action (z-score): IV=1.0743, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=450.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[97] Normalized action (z-score): IV=1.0288, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=400.0000 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[98] Normalized action (z-score): IV=1.0947, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=474.2302 mL, Vaso=-0.0000 mcg/min\n",
      "\n",
      "[99] Normalized action (z-score): IV=1.2649, Vaso=-0.2958\n",
      "    Original action (raw dosage): IV=736.1362 mL, Vaso=-0.0000 mcg/min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ambil beberapa aksi dari batch untuk dicek (misal 5 aksi pertama)\n",
    "actions_np = actions[:100]  # ini dalam domain normalized z-score\n",
    "\n",
    "# Inverse transform ke raw dosage\n",
    "raw_actions = inverse_transform_action(actions_np)\n",
    "\n",
    "# Print hasil\n",
    "for i, (norm_a, raw_a) in enumerate(zip(actions_np, raw_actions)):\n",
    "    print(f\"[{i}] Normalized action (z-score): IV={norm_a[0]:.4f}, Vaso={norm_a[1]:.4f}\")\n",
    "    print(f\"    Original action (raw dosage): IV={raw_a[0]:.4f} mL, Vaso={raw_a[1]:.4f} mcg/min\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set raw IV actions:\n",
      "[[   0.        ]\n",
      " [ 250.        ]\n",
      " [ 500.        ]\n",
      " [ 500.        ]\n",
      " [ 500.        ]\n",
      " [ 272.9995    ]\n",
      " [   0.        ]\n",
      " [ 405.        ]\n",
      " [  95.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [  40.        ]\n",
      " [  40.        ]\n",
      " [  40.        ]\n",
      " [  35.33333333]\n",
      " [  20.        ]\n",
      " [  20.        ]\n",
      " [  20.        ]\n",
      " [  10.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [  14.6764    ]\n",
      " [1030.4714    ]\n",
      " [1005.5       ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [1405.14      ]\n",
      " [ 170.255     ]\n",
      " [1493.57858333]\n",
      " [ 519.709     ]\n",
      " [ 118.6784    ]\n",
      " [  64.67733333]\n",
      " [  40.        ]\n",
      " [  40.        ]\n",
      " [ 648.33333333]\n",
      " [ 666.33333333]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [  15.5       ]\n",
      " [  20.        ]\n",
      " [  17.33333333]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [ 200.92      ]\n",
      " [ 200.92      ]\n",
      " [ 227.62335904]\n",
      " [ 368.06810169]\n",
      " [ 254.62220169]\n",
      " [ 200.00010169]\n",
      " [ 200.00010169]\n",
      " [  67.15460489]\n",
      " [  21.21545065]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [ 206.66666667]\n",
      " [ 450.        ]\n",
      " [ 393.33333333]\n",
      " [ 100.        ]\n",
      " [ 450.        ]\n",
      " [ 400.        ]\n",
      " [ 474.23003333]\n",
      " [ 736.136     ]]\n",
      "Train set raw Vasopressor actions:\n",
      "[[0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.05 ]\n",
      " [0.05 ]\n",
      " [0.05 ]\n",
      " [0.016]\n",
      " [0.016]\n",
      " [0.016]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.18 ]\n",
      " [0.225]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.05 ]\n",
      " [0.08 ]\n",
      " [0.08 ]\n",
      " [0.04 ]\n",
      " [0.04 ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set raw IV actions:\")\n",
    "print(iv_raw[train][:100])\n",
    "\n",
    "print(\"Train set raw Vasopressor actions:\")\n",
    "print(vaso_raw[train][:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Avg Loss: 31.0656, Alpha: 0.0500, Behavior Policy Estimate: 1.0317, WIS Estimate: 0.9842\n",
      "Mean Q1: -0.08, Mean Q2: 0.00, Target Q: 1.02\n",
      "Actor LR: 0.0003\n",
      "Epoch: 0, Batch: 25, Avg Loss: 29.3757, Alpha: 0.0496, Behavior Policy Estimate: 0.9666, WIS Estimate: 0.9626\n",
      "Mean Q1: 0.00, Mean Q2: 0.07, Target Q: 1.10\n",
      "Actor LR: 0.0003\n",
      "Epoch: 0, Batch: 50, Avg Loss: 30.0507, Alpha: 0.0493, Behavior Policy Estimate: 0.9707, WIS Estimate: 0.9681\n",
      "Mean Q1: 0.08, Mean Q2: 0.14, Target Q: 1.19\n",
      "Actor LR: 0.0003\n",
      "Epoch: 0, Batch: 75, Avg Loss: 28.1292, Alpha: 0.0489, Behavior Policy Estimate: 0.9498, WIS Estimate: 0.9461\n",
      "Mean Q1: 0.18, Mean Q2: 0.23, Target Q: 0.99\n",
      "Actor LR: 0.0003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(save_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epoch):\n\u001b[1;32m---> 12\u001b[0m     record \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatchs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     record_loss_z\u001b[38;5;241m.\u001b[39mappend(record)\n\u001b[0;32m     15\u001b[0m     record_a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(record_loss_z)\n",
      "File \u001b[1;32md:\\Algomind_icu\\proposed_model\\SAC_deepQnet.py:614\u001b[0m, in \u001b[0;36mSACAgent.train\u001b[1;34m(self, batches, epoch)\u001b[0m\n\u001b[0;32m    612\u001b[0m actor_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    613\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m--> 614\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;66;03m# ===== Alpha / Entropy Tuning =====\u001b[39;00m\n\u001b[0;32m    617\u001b[0m alpha_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_alpha \u001b[38;5;241m*\u001b[39m (log_prob \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    618\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_entropy)\u001b[38;5;241m.\u001b[39mdetach())\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32md:\\Algomind_icu\\icuvenv\\lib\\site-packages\\torch\\optim\\optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             )\n\u001b[1;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32md:\\Algomind_icu\\icuvenv\\lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32md:\\Algomind_icu\\icuvenv\\lib\\site-packages\\torch\\optim\\adamw.py:220\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    207\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    209\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    210\u001b[0m         group,\n\u001b[0;32m    211\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m         state_steps,\n\u001b[0;32m    218\u001b[0m     )\n\u001b[1;32m--> 220\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32md:\\Algomind_icu\\icuvenv\\lib\\site-packages\\torch\\optim\\optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Algomind_icu\\icuvenv\\lib\\site-packages\\torch\\optim\\adamw.py:782\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    780\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 782\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Algomind_icu\\icuvenv\\lib\\site-packages\\torch\\optim\\adamw.py:376\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    375\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m--> 376\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[0;32m    379\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Model\n",
    "model = SACAgent(state_dim=37, action_dim=2)\n",
    "\n",
    "record_loss_z = []\n",
    "record_phys_q = []\n",
    "record_agent_q = []\n",
    "best_mean_agent_q = -float('inf')\n",
    "save_dir = 'SAC-algorithm/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    record = model.train(batchs, epoch)\n",
    "    record_loss_z.append(record)\n",
    "\n",
    "    record_a = np.array(record_loss_z)\n",
    "    record_b = np.mean(record_a, axis=1)\n",
    "\n",
    "    # --------------------Validation Sets, Evaluation-----------------------\n",
    "    uids = np.unique(bloc_num)\n",
    "    batch_s = ptidvalidat\n",
    "    batch_user = np.isin(bloc_num, batch_s)\n",
    "    state_user = state[batch_user, :]\n",
    "    action_user = action[batch_user]\n",
    "    next_state_user = next_state[batch_user, :]\n",
    "    next_action_user = next_action[batch_user]\n",
    "    reward_user = reward[batch_user]\n",
    "    done_user = done[batch_user]\n",
    "\n",
    "    batch = (state_user, next_state_user, action_user,\n",
    "             next_action_user, reward_user, done_user)\n",
    "\n",
    "    # Panggil do_eval dengan model dan batch\n",
    "    # q_agent, agent_action, phys_action, q_phys = do_eval(model, batch)\n",
    "    # q_phys, q_agent, agent_action, phys_action, agent_log_prob, _ = do_eval(model, batch)\n",
    "    q_phys, q_agent, agent_action, phys_action, agent_log_prob, action_mean, action_std = do_eval(\n",
    "                model, batch)\n",
    "\n",
    "    # Hitung rata-rata Q dari aksi agent dan aksi physician\n",
    "    mean_agent_q = torch.mean(q_agent).item()\n",
    "    mean_phys_q = torch.mean(q_phys).item()\n",
    "\n",
    "    # Tampilkan dan catat\n",
    "    print(\n",
    "        f'Epoch {epoch} - Mean agent Q: {mean_agent_q:.4f}, Mean phys Q: {mean_phys_q:.4f}')\n",
    "\n",
    "    record_phys_q.append(mean_phys_q)\n",
    "    record_agent_q.append(mean_agent_q)\n",
    "\n",
    "    if mean_agent_q > best_mean_agent_q:\n",
    "        best_mean_agent_q = mean_agent_q\n",
    "        best_model_save_path = os.path.join(save_dir, 'best_model_diff_norm.pt')\n",
    "        torch.save({\n",
    "            'actor_state_dict': model.actor.state_dict(),\n",
    "            'critic_1_state_dict': model.critic_1.state_dict(),\n",
    "            'critic_2_state_dict': model.critic_2.state_dict(),\n",
    "            'best_mean_agent_q': best_mean_agent_q\n",
    "        }, best_model_save_path)\n",
    "        print(f'New best model saved with mean agent Q: {best_mean_agent_q}')\n",
    "\n",
    "    print('Agent actions:', agent_action)\n",
    "    print('Physician actions:', phys_action)\n",
    "\n",
    "# ====================== Visualisasi ======================\n",
    "x_length_list = list(range(len(record_b)))\n",
    "plt.figure()\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(x_length_list, record_b)\n",
    "np.save(os.path.join(save_dir, 'loss.npy'), record_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####  Generating test set traces  ####\n",
      "Q_phys avg: 12.676578\n",
      "Q_agent avg: 13.352409\n",
      "Max weight: 0.0004984563222534501\n",
      "WIS Estimated Return: 1.2115\n",
      "Behavior Policy Estimated Return: 0.9173\n",
      "WIS Mean: 1.1190\n",
      "WIS 95% Confidence Interval: (np.float32(1.0137008), np.float32(1.2373433))\n",
      "Time used: 1007.9483441\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert and save record_agent_q\n",
    "record_agent_q_np = [\n",
    "    q.detach().cpu().numpy() if isinstance(q, torch.Tensor) else q\n",
    "    for q in record_agent_q\n",
    "]\n",
    "# Convert the list to a NumPy array\n",
    "record_agent_q_np = np.array(record_agent_q_np)\n",
    "agent_length_list = list(range(len(record_agent_q_np)))\n",
    "plt.plot(agent_length_list, record_agent_q_np, label='record_agent_q')\n",
    "np.save('SAC-algorithm/mean_agent_q.npy', record_agent_q_np)\n",
    "\n",
    "# Convert and save record_phys_q\n",
    "record_phys_q_np = [\n",
    "    q.detach().cpu().numpy() if isinstance(q, torch.Tensor) else q\n",
    "    for q in record_phys_q\n",
    "]\n",
    "record_phys_q_np = np.array(record_phys_q_np)  # Ensure it's a NumPy array\n",
    "phys_length_list = list(range(len(record_phys_q_np)))\n",
    "np.save('SAC-algorithm/mean_phys_q.npy', record_phys_q_np)\n",
    "\n",
    "# Plot configurations (if needed)\n",
    "plt.ylabel(\"mean Q value\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# =================测试集，评估test set================================================================\n",
    "Y90_test = reformat5[test, outcome]\n",
    "SOFA_test = reformat5[test, 57]\n",
    "do_test(model, Xtest, actionbloctest, bloctest,\n",
    "        Y90_test, SOFA_test, reward_value, beta)\n",
    "\n",
    "elapsed = (time.perf_counter() - start)\n",
    "print(\"Time used:\", elapsed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'actor', 'actor_optimizer', 'actor_scheduler', 'alpha', 'alpha_optimizer', 'alpha_scheduler', 'critic_1', 'critic_1_optimizer', 'critic_1_scheduler', 'critic_2', 'critic_2_optimizer', 'critic_2_scheduler', 'device', 'gamma', 'get_action', 'log_alpha', 'soft_update', 'target_critic_1', 'target_critic_2', 'target_entropy', 'tau', 'train']\n"
     ]
    }
   ],
   "source": [
    "print(dir(model))  # Untuk melihat atribut apa saja yang ada pada objek model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "def load_model(model_path, state_dim, action_dim):\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "\n",
    "    # Inisialisasi model SACAgent\n",
    "    model = SACAgent(state_dim=state_dim, action_dim=action_dim)\n",
    "\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "    # Load state_dict ke masing-masing komponen model\n",
    "    model.actor.load_state_dict(checkpoint['actor_state_dict'])\n",
    "    model.critic_1.load_state_dict(checkpoint['critic_1_state_dict'])\n",
    "    model.critic_2.load_state_dict(checkpoint['critic_2_state_dict'])\n",
    "\n",
    "    print(f\"Model loaded successfully from {model_path}\")\n",
    "    print(\n",
    "        f\"Best mean agent Q from training: {checkpoint['best_mean_agent_q']}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from SAC-algorithm/best_model_diff_norm.pt\n",
      "Best mean agent Q from training: 16.717586517333984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_489684\\2278818195.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "model = load_model('SAC-algorithm/best_model_diff_norm.pt', 37, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inverse_transform_action(norm_action, stats_path='SAC-algorithm/action_norm_stats.pkl'):\n",
    "#     with open(stats_path, 'rb') as f:\n",
    "#         stats = pickle.load(f)\n",
    "\n",
    "#     # Ambil statistik yang benar\n",
    "#     mean_log_iv = stats['mean_log_iv']\n",
    "#     std_log_iv = stats['std_log_iv']\n",
    "#     mean_log_vaso = stats['mean_log_vaso']\n",
    "#     std_log_vaso = stats['std_log_vaso']\n",
    "\n",
    "#     # Transformasi balik dari z-score ke log1p domain\n",
    "#     iv_log = norm_action[:, 0] * std_log_iv + mean_log_iv\n",
    "#     vaso_log = norm_action[:, 1] * std_log_vaso + mean_log_vaso\n",
    "\n",
    "#     # Transformasi balik dari log1p ke domain asli\n",
    "#     iv_raw = np.expm1(iv_log)\n",
    "#     vaso_log = np.maximum(vaso_log, 0)  # Tidak boleh log1p dari < 0\n",
    "#     vaso_raw = np.expm1(vaso_log)\n",
    "\n",
    "#     return np.stack([iv_raw, vaso_raw], axis=1)\n",
    "def inverse_transform_action(norm_action, stats_path='SAC-algorithm/action_norm_stats.pkl'):\n",
    "    with open(stats_path, 'rb') as f:\n",
    "        stats = pickle.load(f)\n",
    "\n",
    "    mean_log_iv = stats['mean_log_iv']\n",
    "    std_log_iv = stats['std_log_iv']\n",
    "    mean_log_vaso = stats['mean_log_vaso']\n",
    "    std_log_vaso = stats['std_log_vaso']\n",
    "\n",
    "    # Inverse z-score ke log-domain\n",
    "    iv_log = norm_action[:, 0] * std_log_iv + mean_log_iv\n",
    "    vaso_log = norm_action[:, 1] * std_log_vaso + mean_log_vaso\n",
    "\n",
    "    # Inverse log1p dan ambil abs supaya tidak negatif\n",
    "    iv_raw = np.abs(np.expm1(iv_log))\n",
    "    vaso_raw = np.abs(np.expm1(vaso_log))\n",
    "\n",
    "    return np.stack([iv_raw, vaso_raw], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.91429603 -0.99388236]]\n"
     ]
    }
   ],
   "source": [
    "state = torch.tensor(states[7], dtype=torch.float32).unsqueeze(0)\n",
    "action = model.get_action(state)\n",
    "print(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Tanh Action:      IV=-0.9799, Vaso=-0.9741\n",
      "     Raw Dosage:     IV=1.26 mL, Vaso=0.0894 mcg/min\n",
      "\n",
      "[1] Tanh Action:      IV=-0.6058, Vaso=-0.9846\n",
      "     Raw Dosage:     IV=4.93 mL, Vaso=0.0907 mcg/min\n",
      "\n",
      "[2] Tanh Action:      IV=-0.9659, Vaso=-0.9726\n",
      "     Raw Dosage:     IV=1.34 mL, Vaso=0.0892 mcg/min\n",
      "\n",
      "[3] Tanh Action:      IV=-0.9351, Vaso=-0.9920\n",
      "     Raw Dosage:     IV=1.54 mL, Vaso=0.0917 mcg/min\n",
      "\n",
      "[4] Tanh Action:      IV=-0.5868, Vaso=-0.9937\n",
      "     Raw Dosage:     IV=5.23 mL, Vaso=0.0919 mcg/min\n",
      "\n",
      "[5] Tanh Action:      IV=-0.9658, Vaso=-0.7979\n",
      "     Raw Dosage:     IV=1.35 mL, Vaso=0.0670 mcg/min\n",
      "\n",
      "[6] Tanh Action:      IV=-0.7411, Vaso=-0.9653\n",
      "     Raw Dosage:     IV=3.19 mL, Vaso=0.0883 mcg/min\n",
      "\n",
      "[7] Tanh Action:      IV=-0.9041, Vaso=-0.9747\n",
      "     Raw Dosage:     IV=1.75 mL, Vaso=0.0895 mcg/min\n",
      "\n",
      "[8] Tanh Action:      IV=-0.9892, Vaso=-0.9141\n",
      "     Raw Dosage:     IV=1.21 mL, Vaso=0.0819 mcg/min\n",
      "\n",
      "[9] Tanh Action:      IV=-0.9032, Vaso=-0.6278\n",
      "     Raw Dosage:     IV=1.76 mL, Vaso=0.0448 mcg/min\n",
      "\n",
      "[10] Tanh Action:      IV=-0.9487, Vaso=-0.9648\n",
      "     Raw Dosage:     IV=1.45 mL, Vaso=0.0883 mcg/min\n",
      "\n",
      "[11] Tanh Action:      IV=-0.7662, Vaso=-0.9440\n",
      "     Raw Dosage:     IV=2.92 mL, Vaso=0.0856 mcg/min\n",
      "\n",
      "[12] Tanh Action:      IV=-0.9470, Vaso=-0.9445\n",
      "     Raw Dosage:     IV=1.46 mL, Vaso=0.0857 mcg/min\n",
      "\n",
      "[13] Tanh Action:      IV=-0.2441, Vaso=-0.9393\n",
      "     Raw Dosage:     IV=14.07 mL, Vaso=0.0850 mcg/min\n",
      "\n",
      "[14] Tanh Action:      IV=0.0594, Vaso=-0.9815\n",
      "     Raw Dosage:     IV=31.95 mL, Vaso=0.0904 mcg/min\n",
      "\n",
      "[15] Tanh Action:      IV=-0.7781, Vaso=-0.9914\n",
      "     Raw Dosage:     IV=2.80 mL, Vaso=0.0916 mcg/min\n",
      "\n",
      "[16] Tanh Action:      IV=-0.5092, Vaso=-0.9173\n",
      "     Raw Dosage:     IV=6.61 mL, Vaso=0.0823 mcg/min\n",
      "\n",
      "[17] Tanh Action:      IV=0.3817, Vaso=-0.9280\n",
      "     Raw Dosage:     IV=74.64 mL, Vaso=0.0836 mcg/min\n",
      "\n",
      "[18] Tanh Action:      IV=-0.2097, Vaso=-0.9257\n",
      "     Raw Dosage:     IV=15.47 mL, Vaso=0.0833 mcg/min\n",
      "\n",
      "[19] Tanh Action:      IV=0.3449, Vaso=-0.9789\n",
      "     Raw Dosage:     IV=67.79 mL, Vaso=0.0900 mcg/min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ambil batch dari state\n",
    "states_batch = torch.tensor(states[:100], dtype=torch.float32).to(device)  # (100, state_dim)\n",
    "\n",
    "# Get action dari model: pastikan ini hasil tanh (dalam [-1, 1])\n",
    "with torch.no_grad():\n",
    "    actions_batch = model.get_action(states_batch)  # (100, 2), sudah dalam tanh output\n",
    "\n",
    "# Pindahkan ke CPU dan ubah ke numpy\n",
    "actions_batch_np = actions_batch\n",
    "\n",
    "# Inverse transform ke domain dosis asli\n",
    "original_actions = inverse_transform_action(actions_batch_np)\n",
    "\n",
    "# Cetak contoh hasil\n",
    "for i in range(20):  # Cetak 5 contoh\n",
    "    print(f\"[{i}] Tanh Action:      IV={actions_batch_np[i, 0]:.4f}, Vaso={actions_batch_np[i, 1]:.4f}\")\n",
    "    print(f\"     Raw Dosage:     IV={original_actions[i, 0]:.2f} mL, Vaso={original_actions[i, 1]:.4f} mcg/min\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw model output (tanh): [[[-8.8408351e-01 -9.9720615e-01]\n",
      "  [-9.6430063e-01 -9.9255550e-01]\n",
      "  [-8.4581023e-01 -9.5990509e-01]\n",
      "  [-9.9547148e-01 -8.9644676e-01]\n",
      "  [-9.4396490e-01 -9.7041821e-01]\n",
      "  [-5.5680209e-01 -9.8974395e-01]\n",
      "  [ 1.8493557e-01 -9.8699701e-01]\n",
      "  [-9.9237788e-01 -9.6842790e-01]\n",
      "  [ 9.1869485e-01 -9.4226396e-01]\n",
      "  [-7.5347495e-01 -9.7464073e-01]\n",
      "  [-6.5319484e-01 -9.8211670e-01]\n",
      "  [-9.0633005e-01 -9.4739968e-01]\n",
      "  [-7.8849334e-01 -9.7401667e-01]\n",
      "  [-8.3155274e-01 -9.5057791e-01]\n",
      "  [-8.7693638e-01 -9.7214139e-01]\n",
      "  [-9.8429585e-01 -9.4436061e-01]\n",
      "  [ 9.6928257e-01 -9.9883753e-01]\n",
      "  [-4.0145978e-01 -6.2399071e-01]\n",
      "  [ 9.4807315e-01 -9.7294587e-01]\n",
      "  [ 9.8917663e-01 -9.7972530e-01]\n",
      "  [ 9.2003703e-01 -9.8440921e-01]\n",
      "  [ 9.5035267e-01 -9.9090970e-01]\n",
      "  [ 1.8673158e-01 -9.5742059e-01]\n",
      "  [ 8.3841681e-01 -9.4209236e-01]\n",
      "  [ 7.6127160e-01 -9.8362690e-01]\n",
      "  [-6.2541735e-01 -9.7163165e-01]\n",
      "  [ 7.3042244e-02 -9.6873176e-01]\n",
      "  [-9.0577471e-01 -9.7859198e-01]\n",
      "  [-9.9702066e-01 -9.6470916e-01]\n",
      "  [-9.6967924e-01 -9.2775553e-01]\n",
      "  [-2.2752033e-01 -9.1274202e-01]\n",
      "  [ 1.0124635e-01 -7.8471196e-01]\n",
      "  [-5.9993607e-01 -9.8050797e-01]\n",
      "  [-7.1089971e-01 -9.8901296e-01]\n",
      "  [-9.9292690e-01 -9.9511391e-01]\n",
      "  [-9.9689007e-01 -9.7052991e-01]\n",
      "  [-9.7775292e-01 -8.6136323e-01]\n",
      "  [-9.7186649e-01 -9.0796649e-01]\n",
      "  [-8.9357430e-01 -9.2946368e-01]\n",
      "  [-9.8771262e-01 -9.9259478e-01]\n",
      "  [-9.8619068e-01 -8.4213299e-01]\n",
      "  [-9.9216211e-01 -9.9711055e-01]\n",
      "  [-1.5534754e-01 -8.9364076e-01]\n",
      "  [-9.4617164e-01 -9.8256212e-01]\n",
      "  [-9.2585862e-01 -9.8092848e-01]\n",
      "  [-8.6947399e-01 -9.6192265e-01]\n",
      "  [-3.6396444e-01 -9.8161364e-01]\n",
      "  [-2.7498859e-01 -9.9883670e-01]\n",
      "  [-9.0976620e-01 -9.2698115e-01]\n",
      "  [-9.6903604e-01 -8.9080435e-01]\n",
      "  [-9.6499407e-01 -9.7524017e-01]\n",
      "  [-9.5795733e-01 -9.6560717e-01]\n",
      "  [-4.0303373e-01 -9.6133608e-01]\n",
      "  [-8.9186060e-01 -9.7244918e-01]\n",
      "  [-9.6345955e-01 -8.6266398e-01]\n",
      "  [-8.8180441e-01 -9.2166823e-01]\n",
      "  [-9.7698426e-01 -9.9413544e-01]\n",
      "  [-4.0733907e-01 -9.9140257e-01]\n",
      "  [-9.7252226e-01 -9.5770174e-01]\n",
      "  [-9.4943035e-01 -6.8574810e-01]\n",
      "  [-9.9529880e-01 -9.6413839e-01]\n",
      "  [-8.9340353e-01 -9.0787655e-01]\n",
      "  [-7.2158933e-01 -9.2457217e-01]\n",
      "  [-6.5451080e-01 -9.6382368e-01]\n",
      "  [-7.9508859e-01 -9.2894304e-01]\n",
      "  [-9.1700739e-01 -7.4434382e-01]\n",
      "  [-9.3009096e-01 -9.8737752e-01]\n",
      "  [-3.1553543e-01 -9.1262382e-01]\n",
      "  [ 6.4941680e-01 -9.4865572e-01]\n",
      "  [ 3.8552281e-04 -8.9808005e-01]\n",
      "  [ 2.1404168e-01 -8.6818022e-01]\n",
      "  [ 9.3860215e-01 -7.6926684e-01]\n",
      "  [ 9.9726254e-01 -9.6676385e-01]\n",
      "  [ 4.0216017e-01 -9.8313260e-01]\n",
      "  [ 9.7372305e-01 -7.8040051e-01]\n",
      "  [-4.3463087e-01 -5.2138013e-01]\n",
      "  [-8.2012755e-01 -9.6838415e-01]\n",
      "  [-9.0164149e-01 -7.7750832e-01]\n",
      "  [-9.5858258e-01 -9.6737063e-01]\n",
      "  [ 3.1962237e-01 -9.5915401e-01]\n",
      "  [-3.9977810e-01 -9.7483200e-01]\n",
      "  [-9.8256439e-01 -6.1124671e-01]\n",
      "  [-9.4036740e-01 -8.9592165e-01]\n",
      "  [-9.3167841e-01 -9.6382594e-01]\n",
      "  [-9.3002516e-01 -9.1603428e-01]\n",
      "  [-9.8939425e-01 -9.5317078e-01]\n",
      "  [-9.7443789e-01 -9.5261908e-01]\n",
      "  [-9.4742918e-01 -9.9609524e-01]\n",
      "  [-9.8230749e-01 -9.6223211e-01]\n",
      "  [-9.2051256e-01 -9.9673533e-01]\n",
      "  [-9.2751342e-01 -9.6591818e-01]\n",
      "  [-8.6230320e-01 -9.9082774e-01]\n",
      "  [-8.5181493e-01 -9.1074061e-01]\n",
      "  [-9.6276009e-01 -8.9592004e-01]\n",
      "  [-6.6345704e-01 -9.6744275e-01]\n",
      "  [-8.1600237e-01 -9.4000816e-01]\n",
      "  [-9.9786937e-01 -7.7887678e-01]\n",
      "  [-9.8766536e-01 -9.7793263e-01]\n",
      "  [-8.6773646e-01 -9.3630433e-01]\n",
      "  [-8.5794830e-01 -9.8078460e-01]]]\n",
      "Original action (IV, Vaso): [[[1.89521    1.1629055 ]\n",
      "  [0.08819713 0.09174875]]]\n"
     ]
    }
   ],
   "source": [
    "# Output model (setelah tanh)\n",
    "state = torch.tensor(states[:100], dtype=torch.float32).unsqueeze(0)\n",
    "action = model.get_action(state)\n",
    "# Inverse ke dosis asli (ml/hr dan mcg/min)\n",
    "original_action = inverse_transform_action(action)\n",
    "\n",
    "print(\"Raw model output (tanh):\", action)\n",
    "print(\"Original action (IV, Vaso):\", original_action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.7631459  -0.60842407  0.57550041 ... -0.25306864 -2.29741752\n",
      "  -2.77440114]\n",
      " [ 1.7631459  -0.60842407  0.57550041 ... -0.25306864 -0.27875598\n",
      "  -0.2654923 ]\n",
      " [ 1.7631459  -0.60842407  0.57550041 ... -0.25306864  0.00461083\n",
      "  -0.19041098]\n",
      " ...\n",
      " [-0.42165687 -0.86222085 -2.3190198  ... -0.75606001  0.4277575\n",
      "   0.16129233]\n",
      " [-0.42165687 -0.86222085 -2.3190198  ... -0.75606001  0.44625096\n",
      "   0.18952935]\n",
      " [-0.42165687 -0.86222085 -2.3190198  ... -0.75606001  0.45579092\n",
      "   0.21002294]]\n"
     ]
    }
   ],
   "source": [
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icuvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
